{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c73594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ca28e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke direktori dataset\n",
    "dataset_dir = \"D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset_36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1438109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "207f40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset dan melakukan ekstraksi fitur menggunakan FLBP\n",
    "def extract_features(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith('.bmp'):\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (100, 100))  # Mengubah ukuran gambar menjadi 100x100 pixel\n",
    "            \n",
    "            # Normalisasi gambar\n",
    "            image = image.astype(float) / 255.0\n",
    "            \n",
    "            # Ekstraksi fitur menggunakan FLBP\n",
    "            radius = 3\n",
    "            n_points = 16 * radius\n",
    "            lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "            feature = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))[0]\n",
    "            \n",
    "            images.append(feature)\n",
    "            \n",
    "            # Mendapatkan angka kolestrol dari nama file\n",
    "            cholesterol = filename.split('-')[1]\n",
    "            if cholesterol.isdigit():\n",
    "                labels.append(int(cholesterol))\n",
    "            else:\n",
    "                print(\"Invalid filename format:\", filename)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d94b813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memanggil fungsi untuk melakukan ekstraksi fitur dari dataset menggunakan FLBP\n",
    "images, labels = extract_features(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "745ee1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 382,  144,   96, ...,   97,  399, 4412],\n",
       "       [ 382,  144,   96, ...,   97,  399, 4412],\n",
       "       [ 371,  114,   81, ...,   70,  369, 3854],\n",
       "       ...,\n",
       "       [ 312,  118,   91, ...,   85,  307, 4045],\n",
       "       [ 407,  148,  118, ...,   99,  438, 4847],\n",
       "       [ 407,  148,  118, ...,   99,  438, 4847]], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d79c6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi dataset menjadi data latih dan data uji\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5a8f781b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membangun model regresi linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0ade9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model: 0.6128112606077494\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "score = model.score(X_test, y_test)\n",
    "print(\"Akurasi model:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4677138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan prediksi pada data uji\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Ini untuk 3 Class\n",
    "threshold_low = 200\n",
    "threshold_high = 240\n",
    "\n",
    "# Mengkonversi prediksi menjadi kelas berdasarkan threshold\n",
    "y_pred_classes = np.zeros_like(y_pred)  # Inisialisasi dengan kelas rendah\n",
    "y_pred_classes[y_pred >= threshold_high] = 2  # Kelas tinggi\n",
    "y_pred_classes[(y_pred >= threshold_low) & (y_pred < threshold_high)] = 1  # Kelas beresiko\n",
    "\n",
    "y_test_classes = np.zeros_like(y_test)\n",
    "y_test_classes[y_test >= threshold_high] = 2\n",
    "y_test_classes[(y_test >= threshold_low) & (y_test < threshold_high)] = 1\n",
    "\n",
    "# Evaluasi model\n",
    "confusion_mat = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test_classes, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test_classes, y_pred_classes, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd8b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1 0 0]\n",
      " [1 9 0]\n",
      " [0 0 4]]\n",
      "Accuracy: 0.9333333333333333\n",
      "Precision: 0.9666666666666667\n",
      "Recall: 0.9333333333333333\n",
      "F1-Score: 0.9426900584795322\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bbd702",
   "metadata": {},
   "source": [
    "# Try to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "640d9e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambar berhasil dibaca.\n"
     ]
    }
   ],
   "source": [
    "# Path gambar yang ingin diperiksa\n",
    "image_path = r\"D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset\\normal-187-25-kanan - Copy.bmp\"\n",
    "\n",
    "# Membaca gambar menggunakan cv2.imread()\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Memeriksa apakah gambar berhasil dibaca\n",
    "if image is not None:\n",
    "    print(\"Gambar berhasil dibaca.\")\n",
    "    cv2.imshow(\"Gambar\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Gagal membaca gambar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0ab34a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (200, 200))\n",
    "cv2.imshow(\"Gambar\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad27ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c41191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi Kolesterol: [203.12770741]\n"
     ]
    }
   ],
   "source": [
    "# Coba Predict data\n",
    "# Memuat gambar\n",
    "image_path = r\"D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset\\beresiko-203-22-kiri - Copy.bmp\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (100, 100))  # Mengubah ukuran gambar menjadi 100x100 pixel\n",
    "            \n",
    "# Ekstraksi fitur menggunakan FLBP\n",
    "radius = 6\n",
    "n_points = 16 * radius\n",
    "lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "feature = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))[0]\n",
    "\n",
    "# Mengubah dimensi fitur menjadi bentuk yang dapat diterima oleh model (sesuaikan dengan bentuk fitur yang digunakan saat melatih model)\n",
    "feature = np.reshape(feature, (1, -1))\n",
    "\n",
    "# Melakukan prediksi menggunakan model\n",
    "prediction = model.predict(feature)\n",
    "\n",
    "# Cetak hasil prediksi\n",
    "print(\"Prediksi Kolesterol:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d70cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5b898b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regression_model.h5']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model menggunakan joblib\n",
    "import joblib\n",
    "\n",
    "# Simpan model ke dalam file .h5 menggunakan joblib\n",
    "joblib.dump(model, 'regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "83a0a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muat kembali model dari file .h5\n",
    "model = joblib.load('regression_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0f88f",
   "metadata": {},
   "source": [
    "# OTAK ATIK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a65ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca dataset dan melakukan ekstraksi fitur menggunakan FLBP\n",
    "def extract_features(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(dataset_nya):\n",
    "        if filename.endswith('.bmp'):\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (48, 48))  # Mengubah ukuran gambar menjadi 100x100 pixel\n",
    "            \n",
    "            # Ekstraksi fitur menggunakan FLBP\n",
    "            radius = 3\n",
    "            n_points = 4 * radius\n",
    "            lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "            feature = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))[0]\n",
    "            \n",
    "            images.append(feature)\n",
    "            \n",
    "            # Mendapatkan angka kolestrol dari nama file\n",
    "            cholesterol = filename.split('-')[1]\n",
    "            if cholesterol.isdigit():\n",
    "                labels.append(int(cholesterol))\n",
    "            else:\n",
    "                print(\"Invalid filename format:\", filename)\n",
    "\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432b88e4",
   "metadata": {},
   "source": [
    "# Try to Augmentasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32668486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "dataset_nya = datagen_train.flow_from_directory('D:/@KULIAH SMTR 6/BANGKIT/CAPSTONE/dataset/dataset/',\n",
    "                                                    target_size=(100,100),\n",
    "                                                    color_mode=\"grayscale\",\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6268102",
   "metadata": {},
   "source": [
    "# Build ROI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Fungsi untuk mendapatkan ROI (iris mata) dari gambar mata\n",
    "def get_iris_roi(image):\n",
    "    # Konversi gambar ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Deteksi iris menggunakan algoritma deteksi iris yang sesuai (misalnya, Haar Cascade)\n",
    "    iris_cascade = cv2.CascadeClassifier('path_to_iris_cascade.xml')  # Ganti dengan path file cascade yang sesuai\n",
    "    iris = iris_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    if len(iris) > 0:\n",
    "        # Ambil ROI iris pertama yang terdeteksi\n",
    "        (x, y, w, h) = iris[0]\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        return roi\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Contoh penggunaan\n",
    "image_path = 'path_to_image.jpg'  # Ganti dengan path gambar mata yang ingin digunakan\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Mendapatkan ROI iris mata dari gambar\n",
    "iris_roi = get_iris_roi(image)\n",
    "\n",
    "if iris_roi is not None:\n",
    "    # Menampilkan ROI iris mata\n",
    "    cv2.imshow('Iris ROI', iris_roi)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Iris not found in the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a91ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_iris_roi(image):\n",
    "    # Konversi gambar ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Segmentasi iris menggunakan metode thresholding\n",
    "    ret, threshold = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Menemukan kontur terbesar\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Membuat bounding box untuk kontur iris\n",
    "    x, y, w, h = cv2.boundingRect(iris_contour)\n",
    "\n",
    "    # Mendapatkan ROI iris dari gambar asli\n",
    "    iris_roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    return iris_roi\n",
    "\n",
    "# Membaca gambar mata\n",
    "image = cv2.imread(r'D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset\\normal-187-25-kanan - Copy.bmp')\n",
    "\n",
    "# Mendapatkan ROI iris\n",
    "iris_roi = get_iris_roi(image)\n",
    "\n",
    "# Menampilkan ROI iris\n",
    "cv2.imshow('ROI Iris', iris_roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "236e57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: [11781  2698  1150  2560  2494  2538  2533  2528  2381  2232  2307  2156\n",
      "  1959  2250  2188  2440  2439  2796  3065  3529  4191  4741  5414  5965\n",
      "  5736  6075  5082  4544  3786  3333  2910  2578  2330  2087  2176  2075\n",
      "  1941  2216  2088  2496  2408  2950  2760  3140  2787  2607  1601  1088\n",
      " 15394 88437]\n"
     ]
    }
   ],
   "source": [
    "def get_iris_roi(image):\n",
    "    # Konversi gambar ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Segmentasi iris menggunakan metode thresholding\n",
    "    ret, threshold = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Menemukan kontur terbesar\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Membuat bounding box untuk kontur iris\n",
    "    x, y, w, h = cv2.boundingRect(iris_contour)\n",
    "\n",
    "    # Mendapatkan ROI iris dari gambar asli\n",
    "    iris_roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    return iris_roi\n",
    "\n",
    "def fuzzy_local_binary_pattern(image):\n",
    "    # Konversi gambar ke grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Ekstraksi fitur menggunakan FLBP\n",
    "    radius = 3\n",
    "    n_points = 16 * radius\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    feature = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))[0]\n",
    "\n",
    "    return feature\n",
    "\n",
    "# Membaca gambar mata\n",
    "image = cv2.imread(r'D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset\\normal-187-25-kanan - Copy.bmp')\n",
    "\n",
    "# Mendapatkan ROI iris\n",
    "iris_roi = get_iris_roi(image)\n",
    "\n",
    "# Mengaplikasikan Fuzzy Local Binary Pattern pada ROI iris\n",
    "iris_feature = fuzzy_local_binary_pattern(iris_roi)\n",
    "\n",
    "# Menampilkan hasil\n",
    "cv2.imshow('ROI Iris', iris_roi)\n",
    "print('Feature:', iris_feature)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3deadcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iris_roi(image):\n",
    "    # Konversi gambar ke grayscale jika belum dalam format grayscale\n",
    "    \n",
    "\n",
    "    # Segmentasi iris menggunakan metode thresholding\n",
    "    ret, threshold = cv2.threshold(image, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Menemukan kontur\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) == 0:\n",
    "        # Tidak ada kontur yang ditemukan\n",
    "        raise ValueError(\"No contours found in the image.\")\n",
    "\n",
    "    # Memilih kontur terbesar berdasarkan luas\n",
    "    iris_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Membuat bounding box untuk kontur iris\n",
    "    x, y, w, h = cv2.boundingRect(iris_contour)\n",
    "\n",
    "    # Mendapatkan ROI iris dari gambar asli\n",
    "    iris_roi = image[y:y + h, x:x + w]\n",
    "\n",
    "    return iris_roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8fd82c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_local_binary_pattern(image):\n",
    "    # Ekstraksi fitur menggunakan FLBP\n",
    "    radius = 3\n",
    "    n_points = 16 * radius\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    feature = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))[0]\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0b9f34ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No contours found in the image.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Contoh penggunaan fungsi extract_features\u001b[39;00m\n\u001b[0;32m     34\u001b[0m dataset_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m@KULIAH SMTR 6\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBANGKIT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCAPSTONE\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset_36\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ubah dengan path direktori dataset Anda\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m features, labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, features\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[141], line 16\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(dataset_dir)\u001b[0m\n\u001b[0;32m     13\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m))  \u001b[38;5;66;03m# Mengubah ukuran gambar menjadi 100x100 piksel\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Mendapatkan ROI iris\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m iris_roi \u001b[38;5;241m=\u001b[39m \u001b[43mget_iris_roi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Mengaplikasikan Fuzzy Local Binary Pattern pada ROI iris\u001b[39;00m\n\u001b[0;32m     19\u001b[0m iris_feature \u001b[38;5;241m=\u001b[39m fuzzy_local_binary_pattern(iris_roi)\n",
      "Cell \u001b[1;32mIn[139], line 13\u001b[0m, in \u001b[0;36mget_iris_roi\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      9\u001b[0m contours, _ \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(threshold, cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL, cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contours) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Tidak ada kontur yang ditemukan\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo contours found in the image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Memilih kontur terbesar berdasarkan luas\u001b[39;00m\n\u001b[0;32m     16\u001b[0m iris_contour \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(contours, key\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcontourArea)\n",
      "\u001b[1;31mValueError\u001b[0m: No contours found in the image."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_features(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        if filename.endswith('.bmp'):\n",
    "            image_path = os.path.join(dataset_dir, filename)\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (100, 100))  # Mengubah ukuran gambar menjadi 100x100 piksel\n",
    "            \n",
    "            # Mendapatkan ROI iris\n",
    "            iris_roi = get_iris_roi(image)\n",
    "            \n",
    "            # Mengaplikasikan Fuzzy Local Binary Pattern pada ROI iris\n",
    "            iris_feature = fuzzy_local_binary_pattern(iris_roi)\n",
    "            \n",
    "            images.append(iris_feature)\n",
    "            \n",
    "            # Mendapatkan angka kolestrol dari nama file\n",
    "            cholesterol = filename.split('-')[1]\n",
    "            if cholesterol.isdigit():\n",
    "                labels.append(int(cholesterol))\n",
    "            else:\n",
    "                print(\"Invalid filename format:\", filename)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Contoh penggunaan fungsi extract_features\n",
    "dataset_dir = \"D:\\@KULIAH SMTR 6\\BANGKIT\\CAPSTONE\\dataset\\dataset_36\"  # Ubah dengan path direktori dataset Anda\n",
    "features, labels = extract_features(dataset_dir)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd0c350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
